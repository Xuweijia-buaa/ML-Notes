# 根据行为手动预测ui相关度

## 1 根据用户行为，手动得到用户对item的历史关注度

可以通过用户对item的各种历史行为，得到用户对每个item本身的关注度。作为后续训练的基础。相比直接把是否点击过/是否关注过作为0/1标签，得到的分数会更加准确。后续可以根据得到的<u,i>间的score做回归（当做rating），也可以划分阈值做分类。（如果是非点击率预估任务，单纯是内容排序）

#### 1 定义每种行为本身的权重wi

可以人为配置。是该行为本身的基础权重。比如收藏行为应该比点赞行为权重大一点

如果用户历史上没有某些行为，在计算wi时需重新归一化。比如用户历史上没有分享行为，那么该用户的行为权重向量由[0.2,0.3,0.5],  变成[2/5,3/5,0]==[0,4,0.6,0].   (比如用户A就不喜欢分享，也不喜欢关注。用户A点击行为本身的权重，就会比用户B的点击行为的权重大) 

对于发生过一次分享/没发生过分享， 其他行为完全相同的两个用户A/B。（即原来是A，分享了一个item变成用户B）

 wi不重新调整的话：

对B分享的该item：B对item的得分，相比A只多了一次分享行为本身的得分。w3*1。

对其他item:             B也没有分享行为。和A对该item的的得分相同

wi重新调整：

对B分享的该item：B对item的得分，少于w3*1。因为A的权重重新调整了，A不喜欢分享。所以A对该item的其他2类行为的权重wi增加：w1i/Ni 

对其他item:             都没有分享行为。B的得分少于A。因为权重降低了

可以看出若是根据历史有无该行为调整各行为的基础权重，会对该新增行为本身增加惩罚，使得分享增加的对该item的兴趣分数没那么高。A->B,其他行为的基础权重下降了，对没有发生分享的所有item，分数反而下降了。所以要是鼓励分享的话，还是应该保持行为基础权重不变。不重新分布

| 行为id | 行为名称  | 行为权重 |
| ------ | --------- | -------- |
| 1      | 点击      | w1=0.2   |
| 2      | 关注/收藏 | w2=0.3   |
| 3      | 分享      | w3=0.5   |

#### 2 计算用户对item关注的可能性

具体到用户对某个特定item的关注度得分，体现在用户对该item的每种行为上。可以根据用户对该item的各种行为的的得分，得到用户对该item的总的关注度：

  
$$
score_<u,item>=  \sum_{i} w_i * \frac{n_i}{N_i}
$$
其中i代表第i种行为。w_i是该行为本身的权重。 而$n_i/N_i$代表用户对item该行为的得分。以点击为例。用户对该item的点击次数n_i越多，说明用户越关注该item。但不同用户的活跃度不同，活跃用户总的点击次数较多，他的单次点击的权重就下降了。这里规定用户单次行为i的权重是1/N_i。用户的历史总点击次数越多，单次点击的贡献就降低，起到惩罚作用。因此该用户点击行为对该item的贡献是 $n_i/N_i$,  是该用户点击该item的次数占该用户总的点击次数的比例。再考虑行为本身的基础权重，得到通过该行为，反映出的用户对item的关注度。综合各类行为，得到u对i的总的关注度score。

| 行为id | 用户对该item的该行为次数 | 用户该行为总次数 | 用户单次该行为的权重 | 该行为反映出的用户对该item的关注度 | 考虑行为本身权重，得到该行为反应出的用户对item的关注度 |
| ------ | ------------------------ | ---------------- | -------------------- | ---------------------------------- | ------------------------------------------------------ |
| 1      | n1                       | N1               | 1/N1                 | n1/N1                              | w1*n1/N1                                               |
| 2      | n2                       | N2               | 1/N2                 | n2/N2                              | w2*n2/N2                                               |
| 3      | n3                       | N3               | 1/N3                 | n3/N3                              | w3*n3/N3                                               |

因为wi是一个概率分布，而ni/Ni也是一个概率分布。所以u对i的关注度score,是一个联合概率分布，是用户u关注item i的可能。比如用户点击该item的占比高，用户关注该item的可能性就比较大。或者同一个用户对2物品的行为，相比itemA, itemB对应的分享多一个,点击少一个（n3大，n1小），就说明user对该temB的关注的可能性大一些。 因此该score可以作为内容排序的一个label，学习用户更关注的item的特征。可以当做rating做回归，也可以选一个阈值做2分类。（但N大的时候。每个item的绝对score都很小。阈值不好选择。但可以考虑ranknet, 而不是给单个<u,i>打标）

## 2 根据得分手动矩阵分解

#### 1 把U对I的关注度，手动拆解到标签维度

可以根据该item命中的标签，将上述得到的用户对该item的关注度，拆解到item命中各个标签上。从而基于所有item，得到用户对每个标签本身的关注度，作为用户的标签兴趣度向量

将用户对每个item的关注度，拆解到各个标签维度：

| 用户u  | item_id | <u,i> score | item命中的标签(相当于item的命中标签向量) |
| ------ | ------- | ----------- | ---------------------------------------- |
| <u,i1> | i1      | w1=0.05     | f1=1                                     |
|        |         |             | f2=0                                     |
|        |         |             | f3=0                                     |
| <u,i2> | i2      | w2=0.3      | f1=0                                     |
|        |         |             | f2=1                                     |
|        |         |             | f3=1                                     |

用户对每个item的关注度，可以看做是用户对该item对应的各个标签的关注度的和：
$$
s_{<u,i>}= \sum_{f} u_f *i_f = \vec{u} * \vec{i}
$$
相当于矩阵分解。把score看做用户向量和item向量的乘积，只不过隐向量的每一维都是明确的标签。

| 用户 | item的命中标签向量 | 需要计算u对每个标签的关注度，作为用户向量 | score<u,i> |
| ---- | ------------------ | ----------------------------------------- | ---------- |
| u    | f1                 | u1                                        | sum(ui*fi) |
|      | f2                 | u2                                        |            |
|      | f3                 | u3                                        |            |

$$
i1：       0.05 =  \vec{u} * \vec{i_1}   = u1 * f1  = u1
$$

$$
i2:        0.3  =  \vec{u} * \vec{i_2}    = u2 * f2 + u3 * f3 = u2 + u3
$$

相当于用score去反算向量u。可以通过计算,得到用户对每个标签的关注度（即用户向量）:  [u1，u2，u3]   = [0.05，0.15，0.15]

具体计算：用户u对某个item的关注度s，可以平均拆解到item命中的各标签上。因此每个item的每个标签对s的贡献度是s / N_hits。而用户对每个标签的关注度，是对所有item的该标签的关注度之和。

| 用户对每个标签的关注度 | 用户对i1中每个命中标签的关注度 | 用户对i2中每个命中标签的关注度 | 用户对每个标签的总的关注度 |
| ---------------------- | ------------------------------ | ------------------------------ | -------------------------- |
| u1                     | score1/1                       | 0                              | 0.05/1   +  0  = 0.05      |
| u2                     | 0                              | score2/2                       | 0  +  0.3/2   = 0.15       |
| u3                     | 0                              | score2/2                       | 0  +  0.3/2   = 0.15       |
|                        | score1=0.05 ,N_hits=1          | score2=0.3 ,N_hits=2           |                            |

#### 2 预测用户对新item的score

新的item来了以后，可以直接根据用户标签兴趣度向量 [u1，u2，u3]   ，和该item命中的标签[f1,f2,f3]，得到用户对该新item关注的概率：

新item命中的标签向量: [0,1,1]，   则<u,i>score=0.3        （同i2），

​                                         \[1,1,1]:        <u,i>score=0.35

